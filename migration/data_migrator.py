"""Migrate data from Access database to PostgreSQL."""

import pyodbc
import pandas as pd
import sqlalchemy as sa
from sqlalchemy import create_engine, text
from typing import Dict, List, Any, Optional, Generator
from dataclasses import dataclass
import logging
from tqdm import tqdm
import json
from datetime import datetime
import traceback

from migration_config import MigrationConfig, quote_identifier
from access_analyzer import AccessAnalyzer, DatabaseInfo, TableInfo

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MigrationResult:
    """Result of data migration."""
    success: bool
    tables_migrated: List[str]
    total_rows_migrated: int
    errors: List[str]
    warnings: List[str]
    migration_time: float
    table_results: Dict[str, Dict[str, Any]]

class DataMigrator:
    """Migrate data from Access to PostgreSQL."""
    
    def __init__(self, config: MigrationConfig):
        self.config = config
        self.access_conn = None
        self.pg_engine = None
        
    def connect_access(self):
        """Connect to Access database."""
        try:
            conn_string = self.config.access_config.get_connection_string()
            self.access_conn = pyodbc.connect(conn_string)
            logger.info(f"Connected to Access database: {self.config.access_config.file_path}")
        except Exception as e:
            logger.error(f"Failed to connect to Access database: {e}")
            raise
    
    def connect_postgresql(self):
        """Connect to PostgreSQL database."""
        try:
            conn_string = self.config.postgresql_config.get_connection_string()
            self.pg_engine = create_engine(conn_string)
            logger.info("Connected to PostgreSQL database")
        except Exception as e:
            logger.error(f"Failed to connect to PostgreSQL: {e}")
            raise
    
    def disconnect(self):
        """Disconnect from databases."""
        if self.access_conn:
            self.access_conn.close()
            logger.info("Disconnected from Access database")
        if self.pg_engine:
            self.pg_engine.dispose()
            logger.info("Disconnected from PostgreSQL database")
    
    def get_table_data_batched(self, table_name: str, batch_size: int = 1000) -> Generator[pd.DataFrame, None, None]:
        """Get table data in batches from Access database."""
        cursor = self.access_conn.cursor()
        
        # Get total row count
        try:
            quoted_table = quote_identifier(table_name)
            cursor.execute(f"SELECT COUNT(*) FROM {quoted_table}")
            total_rows = cursor.fetchone()[0]
        except Exception as e:
            logger.error(f"Failed to get row count for {table_name}: {e}")
            return
        
        if total_rows == 0:\n            logger.info(f\"Table {table_name} is empty, skipping\")\n            return\n        \n        # Read data in batches\n        offset = 0\n        while offset < total_rows:\n            try:\n                # Access doesn't support LIMIT/OFFSET, so we use a different approach\n                query = f\"SELECT * FROM {quoted_table}\"\n                df = pd.read_sql(query, self.access_conn)\n                \n                # Manually batch the data\n                batch_start = offset\n                batch_end = min(offset + batch_size, total_rows)\n                \n                if batch_start < len(df):\n                    batch_df = df.iloc[batch_start:batch_end]\n                    if not batch_df.empty:\n                        yield batch_df\n                \n                offset += batch_size\n                \n                # For Access, we need to read all data at once (no native pagination)\n                # So we break after first batch to avoid duplicates\n                if offset >= len(df):\n                    break\n                    \n            except Exception as e:\n                logger.error(f\"Error reading batch from {table_name}: {e}\")\n                break\n    \n    def clean_data_for_postgresql(self, df: pd.DataFrame, table_info: TableInfo) -> pd.DataFrame:\n        \"\"\"Clean and prepare data for PostgreSQL insertion.\"\"\"\n        df_clean = df.copy()\n        \n        # Handle column names (quote if necessary)\n        column_mapping = {}\n        for col in df_clean.columns:\n            clean_col = quote_identifier(col)\n            if clean_col != col:\n                column_mapping[col] = clean_col\n        \n        if column_mapping:\n            df_clean = df_clean.rename(columns=column_mapping)\n        \n        # Handle data type conversions\n        for col_info in table_info.columns:\n            col_name = col_info['name']\n            col_type = col_info['type'].upper()\n            \n            if col_name in df_clean.columns:\n                try:\n                    # Handle boolean columns\n                    if col_type in ['YESNO', 'BOOLEAN']:\n                        df_clean[col_name] = df_clean[col_name].map({True: True, False: False, 1: True, 0: False, 'True': True, 'False': False})\n                    \n                    # Handle date/time columns\n                    elif col_type in ['DATE', 'DATETIME']:\n                        df_clean[col_name] = pd.to_datetime(df_clean[col_name], errors='coerce')\n                    \n                    # Handle numeric columns\n                    elif col_type in ['LONG', 'INTEGER', 'SHORT', 'BYTE']:\n                        df_clean[col_name] = pd.to_numeric(df_clean[col_name], errors='coerce')\n                    \n                    # Handle text columns\n                    elif col_type in ['TEXT', 'MEMO', 'HYPERLINK']:\n                        df_clean[col_name] = df_clean[col_name].astype(str)\n                        # Replace NaN with None for proper NULL handling\n                        df_clean[col_name] = df_clean[col_name].replace('nan', None)\n                    \n                except Exception as e:\n                    logger.warning(f\"Failed to convert column {col_name} in table {table_info.name}: {e}\")\n        \n        # Handle NULL values\n        df_clean = df_clean.where(pd.notnull(df_clean), None)\n        \n        return df_clean\n    \n    def migrate_table_data(self, table_info: TableInfo) -> Dict[str, Any]:\n        \"\"\"Migrate data for a single table.\"\"\"\n        table_name = table_info.name\n        logger.info(f\"Starting data migration for table: {table_name}\")\n        \n        result = {\n            'table_name': table_name,\n            'success': False,\n            'rows_migrated': 0,\n            'errors': [],\n            'warnings': [],\n            'migration_time': 0.0\n        }\n        \n        start_time = datetime.now()\n        \n        try:\n            # Get table data in batches\n            batch_count = 0\n            total_rows = 0\n            \n            # Progress bar\n            progress_desc = f\"Migrating {table_name}\"\n            \n            for batch_df in self.get_table_data_batched(table_name, self.config.batch_size):\n                batch_count += 1\n                batch_size = len(batch_df)\n                \n                # Clean data for PostgreSQL\n                clean_df = self.clean_data_for_postgresql(batch_df, table_info)\n                \n                # Insert batch into PostgreSQL\n                try:\n                    quoted_table = quote_identifier(table_name)\n                    clean_df.to_sql(\n                        quoted_table,\n                        self.pg_engine,\n                        if_exists='append',\n                        index=False,\n                        method='multi',\n                        chunksize=self.config.batch_size\n                    )\n                    \n                    total_rows += batch_size\n                    logger.info(f\"Migrated batch {batch_count} ({batch_size} rows) for {table_name}\")\n                    \n                except Exception as e:\n                    error_msg = f\"Failed to insert batch {batch_count} for {table_name}: {e}\"\n                    result['errors'].append(error_msg)\n                    logger.error(error_msg)\n                    # Continue with next batch\n            \n            result['rows_migrated'] = total_rows\n            result['success'] = len(result['errors']) == 0\n            \n            end_time = datetime.now()\n            result['migration_time'] = (end_time - start_time).total_seconds()\n            \n            logger.info(f\"Completed migration for {table_name}: {total_rows} rows in {result['migration_time']:.2f} seconds\")\n            \n        except Exception as e:\n            error_msg = f\"Migration failed for {table_name}: {e}\"\n            result['errors'].append(error_msg)\n            logger.error(error_msg)\n            logger.error(traceback.format_exc())\n        \n        return result\n    \n    def verify_migration(self, table_name: str) -> Dict[str, Any]:\n        \"\"\"Verify that data was migrated correctly.\"\"\"\n        verification = {\n            'table_name': table_name,\n            'access_count': 0,\n            'postgresql_count': 0,\n            'match': False,\n            'errors': []\n        }\n        \n        try:\n            # Count rows in Access\n            cursor = self.access_conn.cursor()\n            quoted_table = quote_identifier(table_name)\n            cursor.execute(f\"SELECT COUNT(*) FROM {quoted_table}\")\n            verification['access_count'] = cursor.fetchone()[0]\n            \n            # Count rows in PostgreSQL\n            with self.pg_engine.connect() as conn:\n                result = conn.execute(text(f\"SELECT COUNT(*) FROM {quoted_table}\"))\n                verification['postgresql_count'] = result.fetchone()[0]\n            \n            verification['match'] = verification['access_count'] == verification['postgresql_count']\n            \n        except Exception as e:\n            error_msg = f\"Verification failed for {table_name}: {e}\"\n            verification['errors'].append(error_msg)\n            logger.error(error_msg)\n        \n        return verification\n    \n    def migrate_database(self, db_info: DatabaseInfo) -> MigrationResult:\n        \"\"\"Migrate entire database from Access to PostgreSQL.\"\"\"\n        logger.info(\"Starting database migration...\")\n        \n        start_time = datetime.now()\n        \n        tables_migrated = []\n        total_rows_migrated = 0\n        errors = []\n        warnings = []\n        table_results = {}\n        \n        try:\n            self.connect_access()\n            self.connect_postgresql()\n            \n            # Migrate tables in dependency order (tables without foreign keys first)\n            tables_to_migrate = self.order_tables_by_dependencies(db_info.tables)\n            \n            # Create progress bar for overall migration\n            progress_bar = tqdm(tables_to_migrate, desc=\"Migrating tables\")\n            \n            for table_info in progress_bar:\n                progress_bar.set_description(f\"Migrating {table_info.name}\")\n                \n                # Migrate table data\n                table_result = self.migrate_table_data(table_info)\n                table_results[table_info.name] = table_result\n                \n                if table_result['success']:\n                    tables_migrated.append(table_info.name)\n                    total_rows_migrated += table_result['rows_migrated']\n                else:\n                    errors.extend(table_result['errors'])\n                \n                warnings.extend(table_result['warnings'])\n                \n                # Verify migration\n                verification = self.verify_migration(table_info.name)\n                table_result['verification'] = verification\n                \n                if not verification['match']:\n                    warning_msg = f\"Row count mismatch for {table_info.name}: Access={verification['access_count']}, PostgreSQL={verification['postgresql_count']}\"\n                    warnings.append(warning_msg)\n                    logger.warning(warning_msg)\n            \n            progress_bar.close()\n            \n            end_time = datetime.now()\n            migration_time = (end_time - start_time).total_seconds()\n            \n            return MigrationResult(\n                success=len(errors) == 0,\n                tables_migrated=tables_migrated,\n                total_rows_migrated=total_rows_migrated,\n                errors=errors,\n                warnings=warnings,\n                migration_time=migration_time,\n                table_results=table_results\n            )\n            \n        except Exception as e:\n            error_msg = f\"Database migration failed: {e}\"\n            errors.append(error_msg)\n            logger.error(error_msg)\n            logger.error(traceback.format_exc())\n            \n            return MigrationResult(\n                success=False,\n                tables_migrated=tables_migrated,\n                total_rows_migrated=total_rows_migrated,\n                errors=errors,\n                warnings=warnings,\n                migration_time=0.0,\n                table_results=table_results\n            )\n        \n        finally:\n            self.disconnect()\n    \n    def order_tables_by_dependencies(self, tables: List[TableInfo]) -> List[TableInfo]:\n        \"\"\"Order tables by their dependencies (tables without foreign keys first).\"\"\"\n        # Simple ordering: tables without foreign keys first\n        tables_no_fk = []\n        tables_with_fk = []\n        \n        for table in tables:\n            if not table.foreign_keys:\n                tables_no_fk.append(table)\n            else:\n                tables_with_fk.append(table)\n        \n        # TODO: Implement proper topological sorting for complex dependencies\n        return tables_no_fk + tables_with_fk\n\ndef main():\n    \"\"\"Main function to run the data migrator.\"\"\"\n    import sys\n    \n    if len(sys.argv) < 2:\n        print(\"Usage: python data_migrator.py <access_db_path> [postgresql_db_name]\")\n        sys.exit(1)\n    \n    db_path = sys.argv[1]\n    pg_db_name = sys.argv[2] if len(sys.argv) > 2 else \"migrated_db\"\n    \n    # Create configuration\n    from migration_config import AccessConfig, PostgreSQLConfig, MigrationConfig\n    \n    config = MigrationConfig(\n        access_config=AccessConfig(file_path=db_path),\n        postgresql_config=PostgreSQLConfig(database=pg_db_name)\n    )\n    \n    # Analyze Access database\n    analyzer = AccessAnalyzer(config.access_config)\n    db_info = analyzer.analyze_database()\n    \n    # Migrate data\n    migrator = DataMigrator(config)\n    result = migrator.migrate_database(db_info)\n    \n    # Print results\n    print(\"\\n\" + \"=\"*80)\n    print(\"DATA MIGRATION RESULTS\")\n    print(\"=\"*80)\n    \n    print(f\"Success: {result.success}\")\n    print(f\"Tables Migrated: {len(result.tables_migrated)}\")\n    print(f\"Total Rows Migrated: {result.total_rows_migrated:,}\")\n    print(f\"Migration Time: {result.migration_time:.2f} seconds\")\n    print(f\"Errors: {len(result.errors)}\")\n    print(f\"Warnings: {len(result.warnings)}\")\n    \n    if result.tables_migrated:\n        print(f\"\\nMigrated Tables: {', '.join(result.tables_migrated)}\")\n    \n    # Detailed table results\n    print(\"\\nTABLE MIGRATION DETAILS:\")\n    print(\"-\" * 80)\n    for table_name, table_result in result.table_results.items():\n        status = \"✓\" if table_result['success'] else \"✗\"\n        verification = table_result.get('verification', {})\n        match_status = \"✓\" if verification.get('match', False) else \"✗\"\n        \n        print(f\"{status} {table_name}: {table_result['rows_migrated']:,} rows, {table_result['migration_time']:.2f}s, verified: {match_status}\")\n    \n    if result.errors:\n        print(\"\\nERRORS:\")\n        for error in result.errors:\n            print(f\"  - {error}\")\n    \n    if result.warnings:\n        print(\"\\nWARNINGS:\")\n        for warning in result.warnings:\n            print(f\"  - {warning}\")\n    \n    # Save migration report\n    report_file = f\"{db_path}_migration_report.json\"\n    with open(report_file, 'w') as f:\n        # Convert result to serializable format\n        report_data = {\n            'success': result.success,\n            'tables_migrated': result.tables_migrated,\n            'total_rows_migrated': result.total_rows_migrated,\n            'migration_time': result.migration_time,\n            'errors': result.errors,\n            'warnings': result.warnings,\n            'table_results': result.table_results,\n            'migration_date': datetime.now().isoformat()\n        }\n        json.dump(report_data, f, indent=2, default=str)\n    \n    print(f\"\\nMigration report saved to: {report_file}\")\n\nif __name__ == \"__main__\":\n    main()